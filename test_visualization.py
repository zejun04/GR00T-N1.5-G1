#!/usr/bin/env python3
"""
GR00T å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•è§‚æµ‹æ•°æ®å¯è§†åŒ–åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import numpy as np
import cv2
import time
import threading

class TestVisualization:
    def __init__(self):
        self.visualization_running = False
        self.visualization_thread = None
        self.current_observation = None
        self.observation_lock = threading.Lock()

        # å¯åŠ¨å¯è§†åŒ–
        self._start_visualization()

    def _start_visualization(self):
        """å¯åŠ¨å¯è§†åŒ–çº¿ç¨‹"""
        self.visualization_running = True
        self.visualization_thread = threading.Thread(target=self._visualization_loop, daemon=True)
        self.visualization_thread.start()
        print("ğŸ“º å¯åŠ¨æµ‹è¯•å¯è§†åŒ–çª—å£")

    def _stop_visualization(self):
        """åœæ­¢å¯è§†åŒ–çº¿ç¨‹"""
        if self.visualization_running:
            self.visualization_running = False
            if self.visualization_thread and self.visualization_thread.is_alive():
                self.visualization_thread.join(timeout=1.0)
            print("ğŸ“º åœæ­¢æµ‹è¯•å¯è§†åŒ–çª—å£")

    def _visualization_loop(self):
        """å¯è§†åŒ–å¾ªç¯"""
        window_name = "GR00T å¯è§†åŒ–æµ‹è¯• - æŒ‰ 'q' é€€å‡º"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1200, 800)

        try:
            while self.visualization_running:
                with self.observation_lock:
                    observation = self.current_observation

                if observation is not None:
                    display_image = self._create_visualization_image(observation)
                    if display_image is not None:
                        cv2.imshow(window_name, display_image)

                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    self.visualization_running = False
                    break

                time.sleep(0.01)

        except Exception as e:
            print(f"âŒ å¯è§†åŒ–çº¿ç¨‹å‡ºé”™: {e}")
        finally:
            cv2.destroyWindow(window_name)

    def _create_visualization_image(self, observation):
        """åˆ›å»ºå¯è§†åŒ–å›¾åƒ"""
        # ç›¸æœºé…ç½®
        camera_configs = [
            ("video.cam_left_high", "å·¦è‡‚é«˜ä½ç›¸æœº"),
            ("video.cam_left_wrist", "å·¦è‡‚è…•éƒ¨ç›¸æœº"),
            ("video.cam_right_wrist", "å³è‡‚è…•éƒ¨ç›¸æœº")
        ]

        # è·å–æ‰€æœ‰æœ‰æ•ˆçš„ç›¸æœºå›¾åƒ
        valid_images = []
        valid_names = []

        for cam_key, cam_name in camera_configs:
            if cam_key in observation:
                image_data = observation[cam_key]
                if isinstance(image_data, np.ndarray) and image_data.size > 0:
                    processed_img = self._prepare_image_for_display(image_data)
                    if processed_img is not None:
                        valid_images.append(processed_img)
                        valid_names.append(cam_name)

        if not valid_images:
            return self._create_placeholder_image("ç­‰å¾…æµ‹è¯•æ•°æ®...")

        # åˆ›å»º3x1ç½‘æ ¼å¸ƒå±€
        target_width = 400
        target_height = 300
        grid_width = 3 * target_width
        grid_height = target_height
        grid_image = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)

        # è°ƒæ•´å›¾åƒå°ºå¯¸å¹¶å¡«å……ç½‘æ ¼
        for i, (img, name) in enumerate(zip(valid_images, valid_names)):
            if i >= 3:  # æœ€å¤šæ˜¾ç¤º3ä¸ªç›¸æœº
                break

            resized = cv2.resize(img, (target_width, target_height))
            x_start = i * target_width
            x_end = (i + 1) * target_width

            grid_image[0:target_height, x_start:x_end] = resized

            # æ·»åŠ æ ‡ç­¾
            cv2.putText(grid_image, name, (x_start + 10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        # æ·»åŠ çŠ¶æ€ä¿¡æ¯
        timestamp = time.strftime("%H:%M:%S")
        cv2.putText(grid_image, f"GR00Tå¯è§†åŒ–æµ‹è¯• - {timestamp}",
                   (10, grid_height - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        if "annotation.human.action.task_description" in observation:
            task_desc = observation["annotation.human.action.task_description"]
            task_text = f"ä»»åŠ¡: {task_desc[0] if isinstance(task_desc, list) and task_desc else str(task_desc)}"
            cv2.putText(grid_image, task_text, (10, grid_height - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

        return grid_image

    def _prepare_image_for_display(self, image_data):
        """å‡†å¤‡å›¾åƒç”¨äºæ˜¾ç¤º"""
        try:
            if not isinstance(image_data, np.ndarray):
                return None

            if image_data.ndim == 4 and image_data.shape[0] == 1:
                img = image_data[0]
            elif image_data.ndim == 3:
                img = image_data
            else:
                return None

            if img.shape[-1] == 4:
                img = img[..., :3]

            if img.dtype != np.uint8:
                if img.max() <= 1.0:
                    img = (img * 255).astype(np.uint8)
                else:
                    img = img.astype(np.uint8)

            if img.shape[-1] == 3:
                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

            return img
        except Exception as e:
            print(f"âŒ å‡†å¤‡å›¾åƒæ˜¾ç¤ºå‡ºé”™: {e}")
            return None

    def _create_placeholder_image(self, message):
        """åˆ›å»ºå ä½ç¬¦å›¾åƒ"""
        width, height = 1200, 800
        img = np.zeros((height, width, 3), dtype=np.uint8)

        cv2.putText(img, message, (width // 2 - 200, height // 2),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)

        instructions = [
            "GR00T å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•",
            "è¿™ä¸ªçª—å£æ˜¾ç¤ºä»ä»¿çœŸç¯å¢ƒå‘é€ç»™æ¨ç†æœåŠ¡çš„è§‚æµ‹æ•°æ®",
            "æŒ‰ 'q' é”®é€€å‡ºæµ‹è¯•",
            "æµ‹è¯•è„šæœ¬å°†æ¨¡æ‹Ÿè§‚æµ‹æ•°æ®æ›´æ–°"
        ]

        for i, instruction in enumerate(instructions):
            cv2.putText(img, instruction, (50, height - 100 + i * 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)

        return img

    def generate_test_observation(self):
        """ç”Ÿæˆæµ‹è¯•è§‚æµ‹æ•°æ®"""
        # åˆ›å»ºå½©è‰²æµ‹è¯•å›¾åƒ
        def create_test_image(width=640, height=480, pattern="gradient"):
            img = np.zeros((height, width, 3), dtype=np.uint8)

            if pattern == "gradient":
                for i in range(height):
                    for j in range(width):
                        img[i, j, 0] = int(255 * j / width)
                        img[i, j, 1] = int(255 * i / height)
                        img[i, j, 2] = 128
            elif pattern == "chessboard":
                square_size = 50
                for i in range(0, height, square_size):
                    for j in range(0, width, square_size):
                        color = 255 if ((i//square_size + j//square_size) % 2) == 0 else 0
                        img[i:i+square_size, j:j+square_size] = color

            return img[np.newaxis, ...]  # æ·»åŠ batchç»´åº¦

        observation = {
            "video.cam_left_high": create_test_image(pattern="gradient"),
            "video.cam_left_wrist": create_test_image(pattern="chessboard"),
            "video.cam_right_wrist": create_test_image(pattern="gradient"),
            "state.left_arm": np.random.rand(1, 7),
            "state.right_arm": np.random.rand(1, 7),
            "state.left_hand": np.random.rand(1, 6),
            "state.right_hand": np.random.rand(1, 6),
            "state.waist": np.random.rand(1, 3),
            "annotation.human.action.task_description": ["æµ‹è¯•è§‚æµ‹æ•°æ®å¯è§†åŒ–"]
        }

        return observation

    def run_test(self):
        """è¿è¡Œæµ‹è¯•"""
        print("å¼€å§‹GR00Tå¯è§†åŒ–åŠŸèƒ½æµ‹è¯•...")
        print("æŒ‰ 'q' é”®é€€å‡ºæµ‹è¯•çª—å£")

        try:
            for i in range(100):  # è¿è¡Œ100æ¬¡æ›´æ–°
                # ç”Ÿæˆæ–°çš„æµ‹è¯•è§‚æµ‹æ•°æ®
                test_obs = self.generate_test_observation()

                # æ›´æ–°å½“å‰è§‚æµ‹æ•°æ®
                with self.observation_lock:
                    self.current_observation = test_obs

                print(f"æ›´æ–°æµ‹è¯•è§‚æµ‹æ•°æ® #{i+1}")

                # ç­‰å¾…ä¸€æ®µæ—¶é—´
                time.sleep(0.5)

                # æ£€æŸ¥æ˜¯å¦é€€å‡º
                if not self.visualization_running:
                    break

        except KeyboardInterrupt:
            print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")

        finally:
            self._stop_visualization()
            print("æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test = TestVisualization()
    test.run_test()


